# -*- coding: utf-8 -*-
"""Kukus_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/109tLj1DMHrkxiKeeHddi26Oyw0e-ylgG
"""

#Importing the packages that is needs
import tensorflow as tf
import tensorflow_datasets as tfds
import string
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img

#load tensorflow datasets (Will be changed with a local dataset)
(train_data, test_data), ds_info = tfds.load('food101', split=['train', 'validation'], shuffle_files=False, with_info=True, as_supervised=True)

len(train_data), len(test_data)

ds_info.features

#Gatau bakal dipake lagi atau ga kalo misalkan pake dataset lokal soalnya ds_info khusus kalo pake tfds.load
class_names = ds_info.features['label'].names
class_names[:10], len(class_names)

#Menyesuaikan ukuran Image dengan kebutuhan model
def resize_images(image, label):
    image = tf.image.resize(image, size=(224,224))
    image = tf.cast(image, dtype = tf.float32)
    return image, label

train_data = train_data.map(map_func=resize_images, num_parallel_calls=tf.data.AUTOTUNE)
train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)

#test_data doesn't need to be shuffled
test_data = test_data.map(map_func=resize_images, num_parallel_calls=tf.data.AUTOTUNE)
test_data = test_data.batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)

plt.figure(figsize=(16,16))
for i in range(9):
    for image,label in train_data.take(1):
        image = image/255.
        plt.subplot(3,3,i+1)
        plt.imshow(image[0])
        plt.title("Class: " + class_names[label[0].numpy()] + " || Class_label: " + str(label[0].numpy()))
        plt.axis(False);

train_data.element_spec, test_data.element_spec

base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False)
base_model.trainable = False

#Eksekusi ini jika base_model.trainable = True
for layer in model.layers[1].layers:
    if isinstance(layer, layers.BatchNormalization):
        layer.trainable = False

inputs = tf.keras.layers.Input(shape = (224,224,3), name='inputLayer')
x = base_model(inputs, training = False)
x = tf.keras.layers.GlobalAveragePooling2D(name='poolingLayer')(x)
x = tf.keras.layers.Dropout(0.3)(x)
x = tf.keras.layers.Dense(101, name='outputLayer')(x)
outputs = tf.keras.layers.Activation(activation="softmax", dtype=tf.float32, name='activationLayer')(x)

model = tf.keras.Model(inputs, outputs, name = "FeatureExtractionModel")

model.summary()

model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),
              optimizer = tf.keras.optimizers.Adam(0.0001),
              metrics = ["accuracy"])

hist_model = model.fit(train_data,
                       epochs = 10,
                       steps_per_epoch=len(train_data),
                       validation_data=test_data)